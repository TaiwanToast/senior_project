{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from ckip_transformers.nlp import CkipWordSegmenter, CkipPosTagger\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_db_path = '.\\\\chroma_db'\n",
    "\n",
    "db = chromadb.PersistentClient(path=chroma_db_path, settings=Settings(allow_reset=True))\n",
    "db_collection = db.get_or_create_collection(name='pdf_documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 71.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['世界上最透明的故事（日本出版界話題作，只有紙本書可以體驗的感動）.pdf_5', '世界上最透明的故事（日本出版界話題作，只有紙本書可以體驗的感動）.pdf_7']], 'embeddings': None, 'documents': [[None, None]], 'uris': None, 'data': None, 'metadatas': [[{'file_name': '世界上最透明的故事（日本出版界話題作，只有紙本書可以體驗的感動）.pdf', 'text': '道 躋身於 推理 作家 行列 故事 推理 小說 紙本 詭計 世界 透明 故事 故事 編輯 譯者 費盡 心思 小說 中文版 面世 同樣 推理 評論 作家 冒業 身為 電子 書\\n 愛好 割捨 紙本 以前 推給 紙本 氣味 觸感 這些 主觀 感受 現在 紙本 充滿 存在 書手 匠心 獨具 神乎其技 作品 知道 暴雷 期待 更多 一樣 接受 小說 帶來 震撼 感動 電子 推理 雜誌 主編 提醒 嚴禁 暴雷 世界 透明 故事 偵探 小說迷 福音 透明 紙本 書籍 代表 意義 緊張 情節 崩掉 思考 錯過 失去 顛覆 閱讀 極限 機會 高中 圖\\n'}, {'file_name': '世界上最透明的故事（日本出版界話題作，只有紙本書可以體驗的感動）.pdf', 'text': ' 進軍 文藝 書市 神級 話題作 小說家 讀者 拋出 訊息 世界 透明 方式 溫柔 接住 譯者 泥蛙 聲稱 透明 看透 意外 失去 母親 認為 非親非故 血緣 關係 作家 留下 血腥 疑惑 迷霧 穿梭 心緒 扭曲 錯亂 實情 透明 細節 揭露 充滿 驚奇 紙本 呈現 不可 厲害 小\\n 流轉 翻翻 流轉 一些 邪惡 褒義 書籍 需要 紙本 帶來 原汁 原味 體驗 身為 譯者 驚嘆 譯者 文字 運用 讀者 主角 抽絲剝繭 慢慢 拼湊 線索 謎底 揭曉 感動 餘韻 可謂 強烈 探究竟 書痴 下剋上 譯者 作者 編輯 譯\\u3000 建構出 透明 故事'}]], 'distances': [[6.807389888299399, 7.053795909483816]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query = '推理小說'\n",
    "ws_driver = CkipWordSegmenter(device=0)\n",
    "pos_driver = CkipPosTagger(device=0)\n",
    "sentenceModel = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "def ckip_tokenize(text: str) -> str:\n",
    "        def clean(sentence_ws, sentence_pos):\n",
    "            # 這裡只保留名詞和動詞，且去除單一字元\n",
    "            short_sentence = []\n",
    "            stop_pos = set(['Nep', 'Nh', 'Nb'])\n",
    "            for word_ws, word_pos in zip(sentence_ws, sentence_pos):\n",
    "                is_N_or_V = word_pos.startswith(\"V\") or word_pos.startswith(\"N\")\n",
    "                is_not_stop_pos = word_pos not in stop_pos\n",
    "                is_not_one_charactor = not (len(word_ws) == 1)\n",
    "                if is_N_or_V and is_not_stop_pos and is_not_one_charactor:\n",
    "                    short_sentence.append(f\"{word_ws}\")\n",
    "            return \" \".join(short_sentence)\n",
    "        \n",
    "        global ws_driver, pos_driver\n",
    "        ws = ws_driver([text])\n",
    "        pos = pos_driver(ws)\n",
    "        short = clean(ws[0], pos[0])\n",
    "        return short\n",
    "\n",
    "tokenizedQuery = ckip_tokenize(query)\n",
    "queryVector = sentenceModel.encode(tokenizedQuery)\n",
    "\n",
    "searchResult = db_collection.query(query_embeddings=[queryVector],\n",
    "                                    n_results=2)\n",
    "print(searchResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
