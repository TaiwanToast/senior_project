{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ckip_transformers.nlp import CkipWordSegmenter, CkipPosTagger, CkipNerChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing drivers ... WS\n",
      "Initializing drivers ... POS\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing drivers ... WS\")\n",
    "ws_driver = CkipWordSegmenter(device=0)\n",
    "print(\"Initializing drivers ... POS\")\n",
    "pos_driver = CkipPosTagger(device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(sentence_ws, sentence_pos):\n",
    "    # 這裡只保留名詞和動詞，且去除單一字元\n",
    "    short_sentence = []\n",
    "    stop_pos = set(['Nep', 'Nh', 'Nb'])\n",
    "    for word_ws, word_pos in zip(sentence_ws, sentence_pos):\n",
    "        is_N_or_V = word_pos.startswith(\"V\") or word_pos.startswith(\"N\")\n",
    "        is_not_stop_pos = word_pos not in stop_pos\n",
    "        is_not_one_charactor = not (len(word_ws) == 1)\n",
    "        if is_N_or_V and is_not_stop_pos and is_not_one_charactor:\n",
    "            short_sentence.append(f\"{word_ws}\")\n",
    "    return \" \".join(short_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.79it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====\n",
      "推理 小說\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pypdf\n",
    "\n",
    "def main():\n",
    "    # text = [\n",
    "    #     '經過多年激烈戰事，複製人大戰即將結束。絶地議會派歐比王將導致戰亂的主謀者繩之以法；不料，西斯勢力已悄悄深入銀河系，勢力漸大的議長白卜庭用黑暗勢力的力量，誘惑天行者安納金轉變成黑武士達斯維達，幫助他達成心願建立銀河帝國，剷除絕地武士…【星際大戰】系列電影最後一塊拼圖，喬治盧卡斯不僅要解開黑武士的影壇跨世紀謎團，更要著手打造影史最大星際戰爭。'\n",
    "    # ]\n",
    "    text = '推理小說'\n",
    "    # with open('.\\\\product infomation\\\\世界上最透明的故事（日本出版界話題作，只有紙本書可以體驗的感動）.pdf', 'rb') as file:\n",
    "    #     reader = pypdf.PdfReader(file)\n",
    "    #     for page in reader.pages:\n",
    "    #         text += page.extract_text() or ''\n",
    "    ws = ws_driver([text])\n",
    "    pos = pos_driver(ws)\n",
    "    # ner = ner_driver(text)\n",
    "    print()\n",
    "    print('=====')\n",
    "    # print(text)\n",
    "    # print(ws)\n",
    "    short = clean(ws[0], pos[0])\n",
    "    print(short)\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
